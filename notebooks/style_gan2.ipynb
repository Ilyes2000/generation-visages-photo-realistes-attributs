{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105dba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      ">> pip install munch torchmetrics[image] torch-fidelity lpips\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # StarGAN v2 (CelebA-HQ) — Génération & Évaluation (Windows / CPU)\n",
    "# Ce notebook télécharge le repo StarGAN v2, charge les checkpoints CelebA-HQ,\n",
    "# génère des images 256x256, et calcule FID / Inception Score / LPIPS.\n",
    "\n",
    "# %% \n",
    "import os, io, sys, zipfile, requests, glob, json, math, random, shutil, subprocess\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Limiter les threads pour éviter les conflits OpenMP sous Windows\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # en dernier recours si libiomp doublé\n",
    "\n",
    "# Dossiers\n",
    "ROOT      = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\")      # racine projet\n",
    "EXT       = ROOT / \"ext\"\n",
    "EXT.mkdir(parents=True, exist_ok=True)\n",
    "OUT_ROOT  = ROOT / \"runs\" / \"eval_two_models\"\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Chemin des images réelles (FairFace filtrées)\n",
    "REAL_ROOT = ROOT / \"FilteredFaces\"   # -> mets ici ton dossier d'images réelles\n",
    "assert REAL_ROOT.exists(), f\"Le dossier réel {REAL_ROOT} n'existe pas.\"\n",
    "\n",
    "# Réglages généraux\n",
    "SEED        = 123\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "IMG_SIZE    = 256\n",
    "N_GEN       = 200   # commence petit sur CPU; augmente après validation\n",
    "BATCH_GEN   = 8\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device(\"cpu\")   # mets \"cuda\" si GPU\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# Installations indispensables (en cellule séparée si besoin)\n",
    "def pip_install(pkgs):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs\n",
    "    print(\">> pip install\", \" \".join(pkgs))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "pip_install([\"munch\", \"torchmetrics[image]\", \"torch-fidelity\", \"lpips\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857a3ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement du repo StarGAN v2 (ZIP)...\n",
      "OK: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stargan-v2\n",
      "Contenu SGV2: ['assets', 'core', 'metrics']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "SGV2_DIR = EXT / \"stargan-v2\"\n",
    "\n",
    "if not SGV2_DIR.exists():\n",
    "    print(\"Téléchargement du repo StarGAN v2 (ZIP)...\")\n",
    "    url = \"https://github.com/clovaai/stargan-v2/archive/refs/heads/master.zip\"\n",
    "    z = requests.get(url, timeout=60).content\n",
    "    with zipfile.ZipFile(io.BytesIO(z)) as zf:\n",
    "        zf.extractall(EXT)\n",
    "    (EXT / \"stargan-v2-master\").rename(SGV2_DIR)\n",
    "    print(\"OK:\", SGV2_DIR)\n",
    "else:\n",
    "    print(\"Déjà présent:\", SGV2_DIR)\n",
    "\n",
    "# Rendre importables les modules du repo\n",
    "if str(SGV2_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SGV2_DIR))\n",
    "\n",
    "# Optionnel: certains forks utilisent 'core', d'autres 'core.networks' etc.\n",
    "print(\"Contenu SGV2:\", [p.name for p in SGV2_DIR.iterdir() if p.is_dir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cee6851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement → 100000_nets_ema.ckpt\n",
      "  292.8 MB / 292.8 MB (100.0%)\n",
      "OK.\n",
      "Chemin checkpoints: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stargan-v2\\expr\\checkpoints\\celeba_hq | Contenu: ['100000_nets_ema.ckpt']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os, sys, io, requests, zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\")\n",
    "SGV2_DIR = ROOT / \"ext\" / \"stargan-v2\"\n",
    "CKPT_DIR = SGV2_DIR / \"expr\" / \"checkpoints\" / \"celeba_hq\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Liens issus de download.sh (ClovaAI) — on force dl=1 pour un téléchargement direct.\n",
    "URL_CELEBAHQ = \"https://www.dropbox.com/s/96fmei6c93o8b8t/100000_nets_ema.ckpt?dl=1\"\n",
    "\n",
    "def download_file(url: str, dest: Path, chunk=1<<20):\n",
    "    print(f\"Téléchargement → {dest.name}\")\n",
    "    r = requests.get(url, stream=True, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    total = int(r.headers.get(\"content-length\", 0))\n",
    "    done = 0\n",
    "    with open(dest, \"wb\") as f:\n",
    "        for c in r.iter_content(chunk_size=chunk):\n",
    "            if c:\n",
    "                f.write(c); done += len(c)\n",
    "                if total:\n",
    "                    pct = 100*done/total\n",
    "                    print(f\"\\r  {done/1e6:.1f} MB / {total/1e6:.1f} MB ({pct:.1f}%)\", end=\"\")\n",
    "    print(\"\\nOK.\")\n",
    "\n",
    "ckpt_path = CKPT_DIR / \"100000_nets_ema.ckpt\"\n",
    "if not ckpt_path.exists():\n",
    "    download_file(URL_CELEBAHQ, ckpt_path)\n",
    "else:\n",
    "    print(\"Déjà présent:\", ckpt_path)\n",
    "\n",
    "print(\"Chemin checkpoints:\", CKPT_DIR, \"| Contenu:\", [p.name for p in CKPT_DIR.iterdir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c39b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo présent: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stargan-v2\n",
      "Checkpoint présent: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stargan-v2\\expr\\checkpoints\\celeba_hq\\100000_nets_ema.ckpt\n",
      "PyTorch: 2.5.1 | Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# StarGAN v2 (CelebA-HQ) — génération + évaluation (Windows, sans bash)\n",
    "\n",
    "# %%\n",
    "import os, sys, io, requests, zipfile, glob, random\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Chemins à ADAPTER si besoin ---\n",
    "ROOT = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\")\n",
    "REAL_ROOT = ROOT / \"FilteredFaces\"                  # dossier avec tes images FairFace filtrées\n",
    "EXT = ROOT / \"ext\"\n",
    "EXT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Repo StarGAN v2 (si pas déjà extrait)\n",
    "SGV2_DIR = EXT / \"stargan-v2\"\n",
    "if not SGV2_DIR.exists():\n",
    "    print(\"Téléchargement du repo StarGAN v2 (ZIP)…\")\n",
    "    url = \"https://github.com/clovaai/stargan-v2/archive/refs/heads/master.zip\"\n",
    "    z = requests.get(url, timeout=120).content\n",
    "    with zipfile.ZipFile(io.BytesIO(z)) as zf:\n",
    "        zf.extractall(EXT)\n",
    "    (EXT / \"stargan-v2-master\").rename(SGV2_DIR)\n",
    "    print(\"OK:\", SGV2_DIR)\n",
    "else:\n",
    "    print(\"Repo présent:\", SGV2_DIR)\n",
    "\n",
    "# Dossier checkpoints & ckpt CelebA-HQ\n",
    "CKPT_DIR = SGV2_DIR / \"expr\" / \"checkpoints\" / \"celeba_hq\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_FILE = CKPT_DIR / \"100000_nets_ema.ckpt\"\n",
    "\n",
    "# Télécharge le ckpt officiel (équivalent au download.sh)\n",
    "if not CKPT_FILE.exists():\n",
    "    print(\"Téléchargement du checkpoint CelebA-HQ…\")\n",
    "    url_ckpt = \"https://www.dropbox.com/s/96fmei6c93o8b8t/100000_nets_ema.ckpt?dl=1\"\n",
    "    r = requests.get(url_ckpt, stream=True, timeout=300); r.raise_for_status()\n",
    "    with open(CKPT_FILE, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1<<20):\n",
    "            if chunk: f.write(chunk)\n",
    "    print(\"OK:\", CKPT_FILE)\n",
    "else:\n",
    "    print(\"Checkpoint présent:\", CKPT_FILE)\n",
    "\n",
    "# (Optionnel) wing.ckpt si ta révision le demande (sinon on mettra w_hpf=0 et on n'en a pas besoin)\n",
    "# WING_DIR = SGV2_DIR / \"expr\" / \"checkpoints\"\n",
    "# WING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# for url, name in [\n",
    "#     (\"https://www.dropbox.com/s/tjxpypwpt38926e/wing.ckpt?dl=1\", \"wing.ckpt\"),\n",
    "#     (\"https://www.dropbox.com/s/91fth49gyb7xksk/celeba_lm_mean.npz?dl=1\", \"celeba_lm_mean.npz\")\n",
    "# ]:\n",
    "#     p = WING_DIR / name\n",
    "#     if not p.exists():\n",
    "#         print(\"Téléchargement\", name)\n",
    "#         rr = requests.get(url, timeout=120); rr.raise_for_status()\n",
    "#         p.write_bytes(rr.content)\n",
    "\n",
    "# Dépendances métriques\n",
    "import subprocess\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pkgs])\n",
    "\n",
    "pip_install([\"torchmetrics>=1.2.0\", \"lpips\", \"pillow\", \"tqdm\"])\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__, \"| Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71735411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilyes\\AppData\\Local\\Temp\\ipykernel_25964\\574996640.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(str(CKPT_FILE), map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config cible: img_size=256 style_dim=64 latent_dim=16 num_domains=2 w_hpf=0 max_conv_dim=512\n",
      "→ Generator(..., max_conv_dim= 512 )\n",
      "Echec avec variante: {'img_size': 256, 'style_dim': 64, 'w_hpf': 0, 'max_conv_dim': 512} \n",
      "  ↳ RuntimeError('Error(s) in loading state_dict for Generator:\\n\\tsize mismatch for decode.3.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\\n\\tsize mismatch for decode.3.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\\n\\tsize mismatch for decode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.3.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\\n\\tsize mismatch for decode.4.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\\n\\tsize mismatch for decode.4.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.4.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.norm2.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.4.norm2.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.4.conv1x1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\\n\\tsize mismatch for decode.5.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\\n\\tsize mismatch for decode.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\\n\\tsize mismatch for decode.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.norm1.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.5.norm1.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.5.norm2.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\\n\\tsize mismatch for decode.5.norm2.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.5.conv1x1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).')\n",
      "→ Generator(..., max_conv_dim= 1024 )\n",
      "Echec avec variante: {'img_size': 256, 'style_dim': 64, 'w_hpf': 0, 'max_conv_dim': 1024} \n",
      "  ↳ RuntimeError('Error(s) in loading state_dict for Generator:\\n\\tsize mismatch for encode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\\n\\tsize mismatch for encode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for encode.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for encode.4.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for encode.5.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for encode.5.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for encode.5.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for decode.0.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for decode.0.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for decode.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for decode.0.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for decode.0.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([2048, 64]).\\n\\tsize mismatch for decode.0.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for decode.0.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([2048, 64]).\\n\\tsize mismatch for decode.0.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for decode.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for decode.1.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for decode.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\\n\\tsize mismatch for decode.1.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\\n\\tsize mismatch for decode.1.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([2048, 64]).\\n\\tsize mismatch for decode.1.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for decode.1.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([2048, 64]).\\n\\tsize mismatch for decode.1.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for decode.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\\n\\tsize mismatch for decode.2.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([2048, 64]).\\n\\tsize mismatch for decode.2.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\\n\\tsize mismatch for decode.3.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\\n\\tsize mismatch for decode.3.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\\n\\tsize mismatch for decode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.3.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\\n\\tsize mismatch for decode.4.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\\n\\tsize mismatch for decode.4.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.4.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.norm2.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.4.norm2.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.4.conv1x1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\\n\\tsize mismatch for decode.5.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\\n\\tsize mismatch for decode.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\\n\\tsize mismatch for decode.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.norm1.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.5.norm1.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.5.norm2.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\\n\\tsize mismatch for decode.5.norm2.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.5.conv1x1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).')\n",
      "→ Generator(..., max_conv_dim= 576 )\n",
      "Echec avec variante: {'img_size': 256, 'style_dim': 64, 'w_hpf': 0, 'max_conv_dim': 576} \n",
      "  ↳ RuntimeError('Error(s) in loading state_dict for Generator:\\n\\tsize mismatch for encode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 512, 3, 3]).\\n\\tsize mismatch for encode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for encode.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for encode.4.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for encode.5.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for encode.5.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for encode.5.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for decode.0.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for decode.0.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for decode.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for decode.0.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for decode.0.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\\n\\tsize mismatch for decode.0.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\\n\\tsize mismatch for decode.0.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\\n\\tsize mismatch for decode.0.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\\n\\tsize mismatch for decode.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for decode.1.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for decode.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\\n\\tsize mismatch for decode.1.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\\n\\tsize mismatch for decode.1.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\\n\\tsize mismatch for decode.1.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\\n\\tsize mismatch for decode.1.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\\n\\tsize mismatch for decode.1.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\\n\\tsize mismatch for decode.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 576, 3, 3]).\\n\\tsize mismatch for decode.2.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\\n\\tsize mismatch for decode.2.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\\n\\tsize mismatch for decode.3.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\\n\\tsize mismatch for decode.3.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\\n\\tsize mismatch for decode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.3.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.3.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\\n\\tsize mismatch for decode.4.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\\n\\tsize mismatch for decode.4.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.4.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\\n\\tsize mismatch for decode.4.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\\n\\tsize mismatch for decode.4.norm2.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.4.norm2.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.4.conv1x1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\\n\\tsize mismatch for decode.5.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\\n\\tsize mismatch for decode.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\\n\\tsize mismatch for decode.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\\n\\tsize mismatch for decode.5.norm1.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\\n\\tsize mismatch for decode.5.norm1.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for decode.5.norm2.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\\n\\tsize mismatch for decode.5.norm2.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\\n\\tsize mismatch for decode.5.conv1x1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Impossible d'instancier le Generator compatible avec le ckpt.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 103\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# strict=False pour tolérer quelques buffers non-critiques\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m missing_g, unexpected_g \u001b[38;5;241m=\u001b[39m \u001b[43mG_try\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_sd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG chargé | missing=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_g)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unexpected=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unexpected_g)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ilyes\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tsize mismatch for encode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 512, 3, 3]).\n\tsize mismatch for encode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for encode.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for encode.4.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for encode.5.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for encode.5.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for encode.5.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for decode.0.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for decode.0.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for decode.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for decode.0.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for decode.0.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\n\tsize mismatch for decode.0.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for decode.0.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\n\tsize mismatch for decode.0.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for decode.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for decode.1.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for decode.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 576, 3, 3]).\n\tsize mismatch for decode.1.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for decode.1.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\n\tsize mismatch for decode.1.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for decode.1.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\n\tsize mismatch for decode.1.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for decode.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 576, 3, 3]).\n\tsize mismatch for decode.2.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([1152, 64]).\n\tsize mismatch for decode.2.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for decode.3.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for decode.3.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decode.3.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for decode.3.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decode.3.norm2.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\n\tsize mismatch for decode.3.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decode.4.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for decode.4.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decode.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for decode.4.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decode.4.norm1.fc.weight: copying a param with shape torch.Size([1024, 64]) from checkpoint, the shape in current model is torch.Size([512, 64]).\n\tsize mismatch for decode.4.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decode.4.norm2.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for decode.4.norm2.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decode.4.conv1x1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for decode.5.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for decode.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decode.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for decode.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decode.5.norm1.fc.weight: copying a param with shape torch.Size([512, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for decode.5.norm1.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decode.5.norm2.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for decode.5.norm2.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decode.5.conv1x1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m G \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstancier le Generator compatible avec le ckpt.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlast_err\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# MappingNetwork\u001b[39;00m\n\u001b[0;32m    116\u001b[0m M \u001b[38;5;241m=\u001b[39m MappingNetwork(latent_dim, style_dim, num_domains)\u001b[38;5;241m.\u001b[39mto(DEVICE)\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Impossible d'instancier le Generator compatible avec le ckpt."
     ]
    }
   ],
   "source": [
    "# ==== StarGAN v2 (CelebA-HQ) — chargement robuste du ckpt et génération de test (FIX) ====\n",
    "import os, sys, inspect, torch, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# --- chemins à ADAPTER si nécessaire ---\n",
    "SGV2_DIR  = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stargan-v2\")\n",
    "CKPT_FILE = SGV2_DIR / \"expr\" / \"checkpoints\" / \"celeba_hq\" / \"100000_nets_ema.ckpt\"\n",
    "REAL_ROOT = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\FilteredFaces\")  # 1-2 images pour test\n",
    "OUT_DIR   = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\runs\\eval_two_models\\starganv2_celebahq_fix\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert CKPT_FILE.exists(), f\"Checkpoint introuvable: {CKPT_FILE}\"\n",
    "assert SGV2_DIR.exists(), \"Repo StarGAN v2 introuvable\"\n",
    "sys.path.insert(0, str(SGV2_DIR))\n",
    "\n",
    "# Import compatible selon la révision du repo\n",
    "try:\n",
    "    from core.model import Generator, MappingNetwork, StyleEncoder  # révision A\n",
    "except Exception:\n",
    "    from core.networks import Generator, MappingNetwork, StyleEncoder  # révision B\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def strip_module_prefix(sd: dict):\n",
    "    out = {}\n",
    "    for k, v in sd.items():\n",
    "        # ✅ FIX: construire la clé, puis affecter\n",
    "        key = k[len(\"module.\"):] if k.startswith(\"module.\") else k\n",
    "        out[key] = v\n",
    "    return out\n",
    "\n",
    "def first_present(d, keys, default=None):\n",
    "    for k in keys:\n",
    "        if k in d: \n",
    "            return d[k]\n",
    "    return default\n",
    "\n",
    "# 1) Charger ckpt\n",
    "ckpt = torch.load(str(CKPT_FILE), map_location=\"cpu\")\n",
    "root = ckpt.get(\"nets_ema\", ckpt.get(\"state_dict\", ckpt))\n",
    "args = ckpt.get(\"args\", {}) if isinstance(ckpt.get(\"args\", {}), dict) else {}\n",
    "\n",
    "# 2) Lire/hardcoder la config (valeurs CelebA-HQ officielles par défaut)\n",
    "img_size     = int(args.get(\"img_size\", 256))\n",
    "style_dim    = int(args.get(\"style_dim\", 64))\n",
    "latent_dim   = int(args.get(\"latent_dim\", 16))\n",
    "num_domains  = int(args.get(\"num_domains\", 2))\n",
    "w_hpf        = int(args.get(\"w_hpf\", 0))\n",
    "max_conv_dim = int(args.get(\"max_conv_dim\", 512))  # ⭐ critique (512 dans le checkpoint CelebA-HQ)\n",
    "\n",
    "print(f\"Config cible: img_size={img_size} style_dim={style_dim} latent_dim={latent_dim} \"\n",
    "      f\"num_domains={num_domains} w_hpf={w_hpf} max_conv_dim={max_conv_dim}\")\n",
    "\n",
    "# 3) Fabrique un Generator en respectant la signature réelle (max_conv_dim ou F0)\n",
    "def build_generator_try(img_size, style_dim, w_hpf, max_conv_dim):\n",
    "    params = inspect.signature(Generator).parameters\n",
    "    kwargs = {\"w_hpf\": w_hpf}\n",
    "\n",
    "    if \"max_conv_dim\" in params:\n",
    "        kwargs[\"max_conv_dim\"] = max_conv_dim\n",
    "        print(\"→ Generator(..., max_conv_dim=\", max_conv_dim, \")\")\n",
    "        return Generator(img_size, style_dim, **kwargs)\n",
    "\n",
    "    if \"F0\" in params:\n",
    "        # Dans certains forks, F0=64 ~ 512 canaux max\n",
    "        for F0 in (64, 96, 128):\n",
    "            try:\n",
    "                print(f\"→ Generator(..., F0={F0})\")\n",
    "                return Generator(img_size, style_dim, F0=F0, **kwargs)\n",
    "            except TypeError:\n",
    "                continue\n",
    "        print(\"→ Generator(...) sans F0/max_conv_dim (fallback)\")\n",
    "        return Generator(img_size, style_dim, **kwargs)\n",
    "\n",
    "    print(\"→ Generator(...) (signature non standard)\")\n",
    "    return Generator(img_size, style_dim, **kwargs)\n",
    "\n",
    "# 4) Récupérer state_dicts\n",
    "g_sd = first_present(root, [\"generator_ema\",\"generator\",\"G_ema\",\"G\"])\n",
    "m_sd = first_present(root, [\"mapping_network_ema\",\"mapping_network\",\"M_ema\",\"M\"])\n",
    "assert g_sd is not None and m_sd is not None, \"Clés du générateur ou mapping absentes dans le ckpt.\"\n",
    "\n",
    "g_sd = strip_module_prefix(g_sd)\n",
    "m_sd = strip_module_prefix(m_sd)\n",
    "\n",
    "# 5) Essayer différentes variantes jusqu'à ce que le load_state_dict passe\n",
    "variants = [\n",
    "    dict(img_size=img_size, style_dim=style_dim, w_hpf=w_hpf, max_conv_dim=max_conv_dim),  # 512 espéré\n",
    "    dict(img_size=img_size, style_dim=style_dim, w_hpf=w_hpf, max_conv_dim=1024),\n",
    "    dict(img_size=img_size, style_dim=style_dim, w_hpf=w_hpf, max_conv_dim=576),\n",
    "]\n",
    "\n",
    "last_err = None\n",
    "G = None\n",
    "for v in variants:\n",
    "    try:\n",
    "        G_try = build_generator_try(**v).to(DEVICE).eval()\n",
    "        # strict=False pour tolérer quelques buffers non-critiques\n",
    "        missing_g, unexpected_g = G_try.load_state_dict(g_sd, strict=False)\n",
    "        print(f\"G chargé | missing={len(missing_g)} unexpected={len(unexpected_g)}\")\n",
    "        G = G_try\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Echec avec variante:\", v, \"\\n  ↳\", repr(e))\n",
    "        last_err = e\n",
    "        continue\n",
    "\n",
    "if G is None:\n",
    "    raise RuntimeError(\"Impossible d'instancier le Generator compatible avec le ckpt.\") from last_err\n",
    "\n",
    "# MappingNetwork\n",
    "M = MappingNetwork(latent_dim, style_dim, num_domains).to(DEVICE).eval()\n",
    "missing_m, unexpected_m = M.load_state_dict(m_sd, strict=False)\n",
    "print(f\"M chargé | missing={len(missing_m)} unexpected={len(unexpected_m)}\")\n",
    "\n",
    "# 6) Test rapide : générer 2 sorties à partir de 2 vraies images\n",
    "paths = [p for p in REAL_ROOT.rglob(\"*\") if p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\"}]\n",
    "if len(paths) < 2:\n",
    "    raise FileNotFoundError(f\"Il faut au moins 2 images dans {REAL_ROOT} pour le test.\")\n",
    "\n",
    "def load_real_img(p, size=img_size):\n",
    "    tfm = T.Compose([T.Resize(size), T.CenterCrop(size), T.ToTensor()])\n",
    "    return tfm(Image.open(p).convert(\"RGB\")).unsqueeze(0)*2 - 1  # [-1,1]\n",
    "\n",
    "x_src = torch.cat([load_real_img(paths[0]), load_real_img(paths[1])], dim=0).to(DEVICE)\n",
    "y_trg = torch.randint(0, num_domains, (x_src.size(0),), device=DEVICE)\n",
    "z_trg = torch.randn(x_src.size(0), latent_dim, device=DEVICE)\n",
    "with torch.no_grad():\n",
    "    s_trg = M(z_trg, y_trg)\n",
    "    x_fake = G(x_src, s_trg)                      # [-1,1]\n",
    "x_fake = ((x_fake.clamp_(-1,1)+1)/2).cpu().numpy()  # [0,1]\n",
    "\n",
    "for i in range(x_fake.shape[0]):\n",
    "    arr = (x_fake[i].transpose(1,2,0)*255).astype(np.uint8)\n",
    "    Image.fromarray(arr).save(OUT_DIR / f\"demo_{i:02d}.png\")\n",
    "print(\"Images écrites dans:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea23e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
