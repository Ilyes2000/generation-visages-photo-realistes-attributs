{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57145f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab : décommente la ligne suivante\n",
    "# !pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip -q install torchmetrics[image] torch-fidelity lpips gdown tqdm Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ebfc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]\n",
      "OS: Windows-11-10.0.26100-SP0\n",
      "Torch: 2.5.1\n",
      "CUDA dispo ? False\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: exécuter AVANT d'importer torch/numpy\n",
    "import os\n",
    "\n",
    "# Évite le crash OpenMP (duplication lib Intel)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Limite les threads CPU (stabilise sur Windows/Anaconda)\n",
    "os.environ[\"OMP_NUM_THREADS\"]      = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]      = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]  = \"1\"\n",
    "\n",
    "# Maintenant on peut importer en sécurité\n",
    "import sys, platform, random, json, glob, shutil, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA dispo ?\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d125a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\n",
      "EXT : C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\n",
      "MODELS_DIR: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\models\n",
      "OUT_ROOT: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\runs\\eval_two_models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Racine de travail (adapte si besoin)\n",
    "ROOT = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\")\n",
    "EXT  = ROOT / \"ext\"\n",
    "EXT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS_DIR = EXT / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dossiers de sortie pour nos images\n",
    "OUT_ROOT   = ROOT / \"runs\" / \"eval_two_models\"\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"EXT :\", EXT)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)\n",
    "print(\"OUT_ROOT:\", OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca912be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Déjà présent: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stylegan2-ada-pytorch\n"
     ]
    }
   ],
   "source": [
    "import io, zipfile, requests\n",
    "\n",
    "sg2_dir = EXT / \"stylegan2-ada-pytorch\"\n",
    "if not sg2_dir.exists():\n",
    "    print(\"Téléchargement du repo StyleGAN2-ADA (ZIP)…\")\n",
    "    url = \"https://github.com/NVlabs/stylegan2-ada-pytorch/archive/refs/heads/main.zip\"\n",
    "    z = requests.get(url, timeout=60).content\n",
    "    with zipfile.ZipFile(io.BytesIO(z)) as zf:\n",
    "        zf.extractall(EXT)\n",
    "    (EXT / \"stylegan2-ada-pytorch-main\").rename(sg2_dir)\n",
    "    print(\"OK:\", sg2_dir)\n",
    "else:\n",
    "    print(\"Déjà présent:\", sg2_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37560210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Déjà présent: C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\models\\ffhq.pkl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "ffhq_url  = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "ffhq_path = MODELS_DIR / \"ffhq.pkl\"\n",
    "\n",
    "if not ffhq_path.exists():\n",
    "    print(\"Téléchargement de ffhq.pkl…\")\n",
    "    with requests.get(ffhq_url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(ffhq_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1<<20):\n",
    "                if chunk: f.write(chunk)\n",
    "    print(\"OK:\", ffhq_path)\n",
    "else:\n",
    "    print(\"Déjà présent:\", ffhq_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861688b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_dim: 512 | c_dim: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate (CPU):  58%|█████▊    | 58/100 [42:15:28<125:35:50, 10765.49s/it]"
     ]
    }
   ],
   "source": [
    "# === Génération StyleGAN2-ADA (FFHQ) en pur Python / CPU ===\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "sg2_dir   = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\stylegan2-ada-pytorch\")\n",
    "ffhq_path = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\ext\\models\\ffhq.pkl\")\n",
    "out_dir   = Path(r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\runs\\eval_two_models\\stylegan2_ffhq\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 256\n",
    "N_GEN    = 100   # tu peux augmenter ensuite\n",
    "\n",
    "# Import des utilitaires NVIDIA\n",
    "sys.path.insert(0, str(sg2_dir))\n",
    "import legacy  # fourni par le repo NVLabs\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "with open(ffhq_path, \"rb\") as f:\n",
    "    G_ema = legacy.load_network_pkl(f)[\"G_ema\"].to(device).eval()\n",
    "\n",
    "print(\"z_dim:\", G_ema.z_dim, \"| c_dim:\", getattr(G_ema, \"c_dim\", 0))\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "for seed in tqdm(range(N_GEN), desc=\"Generate (CPU)\"):\n",
    "    z = torch.from_numpy(rng.randn(1, G_ema.z_dim)).float().to(device)\n",
    "    c = torch.zeros([1, getattr(G_ema, \"c_dim\", 0)], device=device)\n",
    "    with torch.no_grad():\n",
    "        img = G_ema(z, c, truncation_psi=1.0, noise_mode=\"const\")\n",
    "    # [-1,1] -> [0,255] HWC uint8\n",
    "    img = (img * 127.5 + 128).clamp(0,255).to(torch.uint8)[0].permute(1,2,0).cpu().numpy()\n",
    "    im  = Image.fromarray(img, \"RGB\")\n",
    "    if im.size != (IMG_SIZE, IMG_SIZE):\n",
    "        im = im.resize((IMG_SIZE, IMG_SIZE), Image.LANCZOS)\n",
    "    im.save(out_dir / f\"seed{seed:04d}.png\")\n",
    "\n",
    "print(f\"OK: {N_GEN} images → {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a955e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Évaluation rapide (nécessite torchmetrics[image] et lpips) ====\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import lpips\n",
    "\n",
    "REAL_ROOT = r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\FilteredFaces\"  # ton dossier d'images réelles\n",
    "GEN_ROOT  = r\"C:\\Users\\ilyes\\Downloads\\stylegan2_cond\\runs\\eval_two_models\\stylegan2_ffhq\"\n",
    "IMG_SIZE  = 256\n",
    "\n",
    "ToTensor256 = T.Compose([T.Resize(IMG_SIZE), T.CenterCrop(IMG_SIZE), T.ToTensor()])\n",
    "\n",
    "def iter_folder(folder, batch=32):\n",
    "    paths = sorted(glob.glob(str(Path(folder) / \"*.*\")))\n",
    "    for i in range(0, len(paths), batch):\n",
    "        imgs=[]\n",
    "        for p in paths[i:i+batch]:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            imgs.append(ToTensor256(im))   # [0,1]\n",
    "        yield torch.stack(imgs, 0)\n",
    "\n",
    "def to_uint8(x):\n",
    "    if x.min() < 0: x = (x.clamp(-1,1)+1)/2\n",
    "    return (x*255.0).clamp(0,255).byte()\n",
    "\n",
    "# FID & IS\n",
    "fid = FrechetInceptionDistance(feature=2048)\n",
    "isc = InceptionScore(splits=10, normalize=True)\n",
    "\n",
    "# accumulate REAL\n",
    "for real in iter_folder(REAL_ROOT, batch=32):\n",
    "    fid.update((real*255).to(torch.uint8), real=True)\n",
    "\n",
    "# accumulate FAKE\n",
    "for fake in iter_folder(GEN_ROOT, batch=32):\n",
    "    fid.update((fake*255).to(torch.uint8), real=False)  \n",
    "    isc.update(fake)                                 \n",
    "\n",
    "fid_score            = float(fid.compute().item())\n",
    "is_mean, is_std      = isc.compute()\n",
    "is_mean, is_std      = float(is_mean), float(is_std)\n",
    "print(f\"FID: {fid_score:.3f} | IS: {is_mean:.3f} ± {is_std:.3f}\")\n",
    "\n",
    "# LPIPS diversité\n",
    "loss_fn = lpips.LPIPS(net='alex').eval()\n",
    "paths = sorted(glob.glob(str(Path(GEN_ROOT)/\"*.png\")))\n",
    "pairs = min(400, len(paths)//2)\n",
    "vals=[]\n",
    "for k in range(pairs):\n",
    "    a,b = np.random.choice(len(paths), size=2, replace=False)\n",
    "    A = ToTensor256(Image.open(paths[a]).convert(\"RGB\")).unsqueeze(0)*2-1\n",
    "    B = ToTensor256(Image.open(paths[b]).convert(\"RGB\")).unsqueeze(0)*2-1\n",
    "    with torch.no_grad():\n",
    "        vals.append(float(loss_fn(A,B).item()))\n",
    "print(f\"LPIPS (diversité) mean={np.mean(vals):.4f} ± {np.std(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
