# üß™ FairFace cStyleGAN2-ADA (Conditionnel) ‚Äî D√©mo Gradio + StarGAN-v2 & SD2.1

Ce d√©p√¥t permet de **pr√©parer vos donn√©es FairFace**, **entra√Æner un StyleGAN2-ADA conditionnel** (√Çge / Genre / Ethnie), **charger des checkpoints pr√©-entra√Æn√©s** (FFHQ, StarGAN-v2), et **lancer une interface Gradio** (th√®me sombre) pour g√©n√©rer/√©diter des visages.  
En bonus : **Stable Diffusion 2.1 img2img** pour l‚Äô√©dition guid√©e par texte.

---

## üî∞ TL;DR (d√©marrage rapide)

### Windows (Conda)
```powershell
conda create -n facegan python=3.10 -y
conda activate facegan
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio
python -m pip install --upgrade pip
pip install -r requirements.txt
pip install ftfy regex tqdm
pip install "git+https://github.com/openai/CLIP.git"
pip install diffusers transformers accelerate safetensors

$env:KMP_DUPLICATE_LIB_OK="TRUE"
$env:OMP_NUM_THREADS="1"; $env:MKL_NUM_THREADS="1"; $env:OPENBLAS_NUM_THREADS="1"; $env:NUMEXPR_NUM_THREADS="1"

# (Option) SD2.1 priv√© : huggingface-cli login
```

### Linux / macOS (venv)
```bash
python -m venv .venv && source .venv/bin/activate
pip install --upgrade pip
# CUDA si GPU :
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
# ou CPU :
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
pip install ftfy regex tqdm "git+https://github.com/openai/CLIP.git"
pip install diffusers transformers accelerate safetensors
```

---

## üóÇÔ∏è Arborescence conseill√©e
```
stylegan2_cond/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îî‚îÄ‚îÄ gradio_demo.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ fairface_filtered/
‚îÇ       ‚îú‚îÄ‚îÄ images/               # vos images (centr√©es, 256x256)
‚îÇ       ‚îî‚îÄ‚îÄ labels.csv            # filename,age_bin,gender,ethnicity
‚îú‚îÄ‚îÄ ext/
‚îÇ   ‚îú‚îÄ‚îÄ stargan_ckpt/             # optionnel (StarGAN-v2)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 100000_nets_ema.ckpt
‚îÇ   ‚îî‚îÄ‚îÄ sd/                       # optionnel (cache diffusers)
‚îú‚îÄ‚îÄ runs/
‚îÇ   ‚îú‚îÄ‚îÄ training/                 # logs/ckpts d'entra√Ænement SG2-ADA
‚îÇ   ‚îî‚îÄ‚îÄ demo_outputs/             # images sorties Gradio
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ sg2ada_fairface.pkl       # snapshot G_ema (si entra√Æn√©)
‚îÇ   ‚îî‚îÄ‚îÄ ffhq.pkl                  # optionnel (pr√©-entra√Æn√© NVIDIA)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üì¶ `requirements.txt` minimal
```txt
numpy>=1.23
pillow>=10.0
opencv-python
torchmetrics
matplotlib
tqdm
pandas
scikit-image
gradio==4.44.1
fastapi<0.115
starlette<0.39
gradio_client>=0.16
munch
einops
protobuf<5
```

> üí° Si vous voyez **`OMP: Error #15`** (Windows), exportez avant de lancer :  
> `KMP_DUPLICATE_LIB_OK=TRUE`, `OMP_NUM_THREADS=1`, `MKL_NUM_THREADS=1`, `OPENBLAS_NUM_THREADS=1`, `NUMEXPR_NUM_THREADS=1`.

---

## üßπ Pr√©parer FairFace (‚Üí 256√ó256)

1. T√©l√©chargez **FairFace** et un **CSV d‚Äôannotations** (`age`, `gender`, `race`).  
2. Filtrez et exportez en **256√ó256** centr√©s visage.  
3. Cr√©ez `data/fairface_filtered/images/*.jpg` + `data/fairface_filtered/labels.csv` :

```csv
filename,age_bin,gender,ethnicity
000001.jpg,0,1,3
000002.jpg,2,0,6
...
```

- `age_bin ‚àà {0..4}` (ex: 18‚Äì29, 30‚Äì39, 40‚Äì49, 50‚Äì59, 60+)  
- `gender ‚àà {0: Male, 1: Female}`  
- `ethnicity ‚àà {0..6}` (White, Black, Latino_Hispanic, East_Asian, Southeast_Asian, Indian, Middle_Eastern)

---

## üèãÔ∏è‚Äç‚ôÄÔ∏è Entra√Æner StyleGAN2-ADA (conditionnel)

### (Option) Convertir en dataset `.zip` style NVIDIA
```bash
python dataset_tool.py --source=data/fairface_filtered/images                        --dest=data/fairface_256.zip                        --resolution=256x256
```

### Lancer l‚Äôentra√Ænement
```bash
python train.py   --outdir=runs/training/sg2ada_fairface256   --data=data/fairface_256.zip   --gpus=1 --batch=64 --cfg=stylegan2 --cbase=32768 --cmax=512   --gamma=10 --kimg=6000 --snap=50 --cond=1
```

√Ä la fin, copiez le meilleur snapshot en :
```
models/sg2ada_fairface.pkl
```

---

## ‚ñ∂Ô∏è Lancer l‚ÄôUI Gradio

### Windows PowerShell
```powershell
conda activate facegan
$env:KMP_DUPLICATE_LIB_OK="TRUE"
$env:OMP_NUM_THREADS="1"; $env:MKL_NUM_THREADS="1"; $env:OPENBLAS_NUM_THREADS="1"; $env:NUMEXPR_NUM_THREADS="1"
cd apps
python gradio_demo.py ^
  --fairface_pkl "..\models\sg2ada_fairface.pkl" ^
  --ffhq_pkl "..\modelsfhq.pkl" ^
  --stargan_ckpt "..\ext\stargan_ckpt@000_nets_ema.ckpt" ^
  --sd_model "stabilityai/stable-diffusion-2-1" ^
  --out_dir "..
uns\demo_outputs"
```

### Linux / macOS
```bash
source .venv/bin/activate  # ou conda activate facegan
cd apps
python gradio_demo.py   --fairface_pkl ../models/sg2ada_fairface.pkl   --ffhq_pkl ../models/ffhq.pkl   --stargan_ckpt ../ext/stargan_ckpt/100000_nets_ema.ckpt   --sd_model "stabilityai/stable-diffusion-2-1"   --out_dir ../runs/demo_outputs
```

- Ouverture par d√©faut : **http://127.0.0.1:7860**  
- Si votre `localhost` est bloqu√© : lancer avec `share=True` (ou corriger le proxy).

---

## üñ±Ô∏è Utilisation de l‚ÄôUI

### Panneau 1 ‚Äî StyleGAN2-ADA (FairFace)
- Upload image (optionnel) ou g√©n√©ration *from scratch*.
- S√©lectionnez **√Çge / Genre / Ethnie** ‚Üí **G√©n√©rer**.
- Sorties dans `runs/demo_outputs/`.

### Panneau 2 ‚Äî StarGAN-v2 (CelebA-HQ) *(optionnel)*
- N√©cessite `ext/stargan_ckpt/100000_nets_ema.ckpt`.
- √âdite surtout **√Çge** et **Genre** selon le checkpoint.

### Panneau 3 ‚Äî Stable Diffusion 2.1 img2img *(optionnel)*
- Upload image + sliders d‚Äôattributs ‚Üí prompt auto-g√©n√©r√©.
- Param√®tre `strength` (0.3‚Äì0.6 = conserve la structure, change les traits).

---

## üß© Checkpoints & ressources

- **FFHQ** : `models/ffhq.pkl` (test inf√©rence SG2 g√©n√©rique).  
- **StarGAN-v2** : `ext/stargan_ckpt/100000_nets_ema.ckpt`.  
- **SD2.1** : `stabilityai/stable-diffusion-2-1` (token HF si requis).

---

## üõ†Ô∏è D√©pannage (FAQ)

- **`OMP: Error #15` (Windows)** ‚Üí Exportez : `KMP_DUPLICATE_LIB_OK=TRUE` + limites de threads.  
- **Gradio ‚Üí `TypeError: argument of type 'bool' is not iterable`** ‚Üí √âpinglez : `gradio==4.44.1`, `fastapi<0.115`, `starlette<0.39>`.  
- **`ModuleNotFoundError: No module named 'clip'`** ‚Üí Installez Git puis : `pip install "git+https://github.com/openai/CLIP.git"` (ou `open-clip-torch`).  
- **`FileNotFoundError: ... sg2ada_fairface.pkl`** ‚Üí V√©rifiez `--fairface_pkl`.  
- **Diffusers / HF** ‚Üí `huggingface-cli login` si le mod√®le n‚Äôest pas public.  
- **CUDA non d√©tect√©** ‚Üí Build PyTorch **compatible** avec votre CUDA.

---

## üîÅ Reproductibilit√©

- Logguez `seed` + hyperparam√®tres (`batch`, `kimg`, `gamma`, `cond`) dans `runs/training/...`.  
- Exportez **FID / pertes / R1 / ADA** depuis vos notebooks.  
- Versionnez les scripts + snapshots `.pkl`.

---

## ‚öñÔ∏è √âthique & conformit√©

- Datasets licites (FairFace, CelebA-HQ, FFHQ).  
- Transparence des **biais** (analyse par sous-groupes).  
- Pas d‚Äôusage sur personnes r√©elles sans consentement.

---

## üìú Licence

- Code de recherche : **licence acad√©mique non-commerciale** (adaptez si besoin).  
- Respectez les licences **StyleGAN2-ADA**, **StarGAN-v2**, **Diffusers/Stable Diffusion**.

---

## üß± (Optionnel) Scripts pr√™ts √† l‚Äôemploi

### `scripts/setup_windows.ps1`
```powershell
param(
  [string]$EnvName="facegan",
  [string]$CudaIndexUrl="https://download.pytorch.org/whl/cu121"
)
conda create -n $EnvName python=3.10 -y
conda activate $EnvName
pip install --index-url $CudaIndexUrl torch torchvision torchaudio
python -m pip install --upgrade pip
pip install -r requirements.txt
pip install ftfy regex tqdm
pip install "git+https://github.com/openai/CLIP.git"
pip install diffusers transformers accelerate safetensors
$env:KMP_DUPLICATE_LIB_OK="TRUE"
$env:OMP_NUM_THREADS="1"; $env:MKL_NUM_THREADS="1"; $env:OPENBLAS_NUM_THREADS="1"; $env:NUMEXPR_NUM_THREADS="1"
Write-Host "OK"
```

### `scripts/setup_unix.sh`
```bash
#!/usr/bin/env bash
set -e
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
pip install ftfy regex tqdm "git+https://github.com/openai/CLIP.git"
pip install diffusers transformers accelerate safetensors
echo "OK"
```

### `scripts/run_gradio_windows.ps1`
```powershell
param(
  [string]$FairfacePkl="..\models\sg2ada_fairface.pkl",
  [string]$FfhqPkl="..\modelsfhq.pkl",
  [string]$StarGanCkpt="..\ext\stargan_ckpt@000_nets_ema.ckpt",
  [string]$SdModel="stabilityai/stable-diffusion-2-1",
  [string]$OutDir="..
uns\demo_outputs"
)
conda activate facegan
$env:KMP_DUPLICATE_LIB_OK="TRUE"
$env:OMP_NUM_THREADS="1"; $env:MKL_NUM_THREADS="1"; $env:OPENBLAS_NUM_THREADS="1"; $env:NUMEXPR_NUM_THREADS="1"
cd apps
python gradio_demo.py --fairface_pkl $FairfacePkl --ffhq_pkl $FfhqPkl --stargan_ckpt $StarGanCkpt --sd_model $SdModel --out_dir $OutDir
```

### `scripts/run_gradio_unix.sh`
```bash
#!/usr/bin/env bash
set -e
source .venv/bin/activate 2>/dev/null || conda activate facegan
cd apps
python gradio_demo.py   --fairface_pkl ../models/sg2ada_fairface.pkl   --ffhq_pkl ../models/ffhq.pkl   --stargan_ckpt ../ext/stargan_ckpt/100000_nets_ema.ckpt   --sd_model "stabilityai/stable-diffusion-2-1"   --out_dir ../runs/demo_outputs
```

---

## üìå R√©capitulatif commandes

```bash
# (Windows) cr√©er env + installer
conda create -n facegan python=3.10 -y
conda activate facegan
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio
pip install -r requirements.txt
pip install ftfy regex tqdm "git+https://github.com/openai/CLIP.git"
pip install diffusers transformers accelerate safetensors

# (Option) pr√©parer dataset stylegan
python dataset_tool.py --source=data/fairface_filtered/images --dest=data/fairface_256.zip --resolution=256x256

# entra√Æner SG2-ADA conditionnel
python train.py --outdir=runs/training/sg2ada_fairface256 --data=data/fairface_256.zip   --gpus=1 --batch=64 --cfg=stylegan2 --cbase=32768 --cmax=512 --gamma=10 --kimg=6000 --snap=50 --cond=1

# lancer Gradio
cd apps
python gradio_demo.py --fairface_pkl ../models/sg2ada_fairface.pkl --ffhq_pkl ../models/ffhq.pkl   --stargan_ckpt ../ext/stargan_ckpt/100000_nets_ema.ckpt --sd_model "stabilityai/stable-diffusion-2-1"   --out_dir ../runs/demo_outputs
```
